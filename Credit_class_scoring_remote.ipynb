{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azureml-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scikit-learn==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade imbalanced-learn==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azureml-interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install interpret-community[visualization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version: 1.30.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "\n",
    "print(f\"Azure ML SDK Version: {azureml.core.VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='sandboxaml', subscription_id='f80606e5-788f-4dc3-a9ea-2eb9a7836082', resource_group='rg-sandbox')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version: 0.24.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "print(f\"Azure ML SDK Version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'exp_german_credit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>exp_german_credit</td><td>sandboxaml</td><td><a href=\"https://ml.azure.com/experiments/id/f8a8e673-d7d3-4884-af21-29a225b0b856?wsid=/subscriptions/f80606e5-788f-4dc3-a9ea-2eb9a7836082/resourcegroups/rg-sandbox/workspaces/sandboxaml&amp;tid=8e2e7c2d-4702-496d-af6c-96e4bfc9f667\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: exp_german_credit,\n",
       "Workspace: sandboxaml)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target_name = \"compute-cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cluster already exists\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Compute target creation\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "    print(\" Cluster already exists\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           min_nodes=0, max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True, min_node_count=0, timeout_in_minutes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "# Retrieve existing compute target\n",
    "\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "\n",
    "compute_target = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "print(compute_target.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix,  plot_roc_curve, f1_score, recall_score\n",
    "from sklearn import preprocessing\n",
    "#from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE\n",
    "import joblib\n",
    "#import pickle\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "#from utils import load_data\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "exp = run.experiment\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--penalty', type=str, default='l2', help='norm')\n",
    "parser.add_argument('--max_iter', type=int, default=10000, help='iterations')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"Argument 1: %s\" % args.penalty)\n",
    "print(\"Argument 2: %s\" % args.max_iter)\n",
    "\n",
    "dataset_name = 'German Credit'\n",
    "dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "df = dataset.to_pandas_dataframe()\n",
    "\n",
    "#df.drop(\"id\", axis=1, inplace=True) # d'o√π vient la variable id ? du dataset Azure ML ?\n",
    "df[\"class\"] = [1 if x == \"good\" else 0 for x in df[\"class\"]]\n",
    "\n",
    "credit_train, credit_test = train_test_split(df, test_size=0.2)\n",
    "Y_train = credit_train[\"class\"]\n",
    "credit_train.drop(\"class\", axis=1, inplace=True)\n",
    "\n",
    "Y_test = credit_test[\"class\"]\n",
    "credit_test.drop(\"class\", axis=1, inplace=True)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "\n",
    "for c in credit_train:\n",
    "    X_train[c] = le.fit_transform(credit_train[c])\n",
    "    X_test[c] = le.fit_transform(credit_test[c])\n",
    "    \n",
    "# Basic logistic regression\n",
    "model = LogisticRegression(penalty='l2', max_iter=10000).fit(X=X_train, y=Y_train)\n",
    "print(\"Train accuracy : {}\".format(model.score(X_train, Y_train)))\n",
    "print(\"Test accuracy : {}\".format(model.score(X_test, Y_test)))\n",
    "\n",
    "plot_confusion_matrix(model, X_test, Y_test, cmap=\"binary\")\n",
    "\n",
    "#plot_roc_curve(model, X_test, Y_test)\n",
    "#plt.show()\n",
    "\n",
    "print(\"Recall : {}\".format(recall_score(model.predict(X_test), Y_test)))\n",
    "print(\"F1 : {}\".format(f1_score(model.predict(X_test), Y_test)))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/german_credit_log_remote_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix,  plot_roc_curve, f1_score, recall_score\n",
    "from sklearn import preprocessing\n",
    "#from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE\n",
    "import joblib\n",
    "#import pickle\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "#from utils import load_data\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "exp = run.experiment\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--penalty', type=str, default='l2', help='norm')\n",
    "parser.add_argument('--max_iter', type=int, default=10000, help='iterations')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"Argument 1: %s\" % args.penalty)\n",
    "print(\"Argument 2: %s\" % args.max_iter)\n",
    "\n",
    "dataset_name = 'German Credit'\n",
    "dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "df = dataset.to_pandas_dataframe()\n",
    "\n",
    "#df.drop(\"id\", axis=1, inplace=True) # d'o√π vient la variable id ? du dataset Azure ML ?\n",
    "df[\"class\"] = [1 if x == \"good\" else 0 for x in df[\"class\"]]\n",
    "\n",
    "credit_train, credit_test = train_test_split(df, test_size=0.2)\n",
    "Y_train = credit_train[\"class\"]\n",
    "credit_train.drop(\"class\", axis=1, inplace=True)\n",
    "\n",
    "Y_test = credit_test[\"class\"]\n",
    "credit_test.drop(\"class\", axis=1, inplace=True)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "\n",
    "for c in credit_train:\n",
    "    X_train[c] = le.fit_transform(credit_train[c])\n",
    "    X_test[c] = le.fit_transform(credit_test[c])\n",
    "\n",
    "mlflow_uri = ws.get_mlflow_tracking_uri()\n",
    "print(f\"MLflow URI : {mlflow_uri}\")\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "mlflow.set_experiment(exp.name)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.log_param(\"penalty\", args.penalty)\n",
    "    mlflow.log_param(\"max_iter\", args.max_iter)\n",
    "\n",
    "    model = LogisticRegression(penalty='l2', max_iter=10000).fit(X=X_train, y=Y_train)\n",
    "    \n",
    "    train_accuracy = model.score(X_train, Y_train)\n",
    "    test_accuracy = model.score(X_test, Y_test)\n",
    "    mlflow.log_metric(\"train accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"test accuracy\", test_accuracy)\n",
    "    print(\"Train accuracy : {}\".format(train_accuracy))\n",
    "    print(\"Test accuracy : {}\".format(test_accuracy))\n",
    "\n",
    "    cm_image = plot_confusion_matrix(model, X_test, Y_test, cmap=\"binary\")\n",
    "    rc_image = plot_roc_curve(model, X_test, Y_test)\n",
    "    \n",
    "    # Log artifacts (output files)\n",
    "    #mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "    #mlflow.log_artifact(\"roc_curve.png\")\n",
    "\n",
    "    recall = recall_score(model.predict(X_test), Y_test)\n",
    "    f1 = f1_score(model.predict(X_test), Y_test)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    print(\"Recall : {}\".format(recall))\n",
    "    print(\"F1 : {}\".format(f1))\n",
    "    \n",
    "    # NE CREE PAS D'ARTEFACT ? il faudrait utiliser model.register ou run.register_model\n",
    "    mlflow.sklearn.log_model(model, \"german_credit_mlflow_log_model\")\n",
    "    \n",
    "    # ENREGISTRE LE MODELE EN LOCAL\n",
    "    modelpath = f\"german_credit/log_model-{args.penalty}-{args.max_iter}.pkl\"\n",
    "    mlflow.sklearn.save_model(model, modelpath)\n",
    "    \n",
    "    azureml_model = run.register_model(model_name='german_credit_mlflow_log_model',\n",
    "                                              model_path=\"german_credit_mlflow_log_model/model.pkl\",\n",
    "                                              tags={},\n",
    "                                              description=\"Model saved with MLflow sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/media/how-to-track-experiments/mlflow-diagram-track.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "trainenv = Environment('german-credit-training-env')\n",
    "trainenv.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-defaults',\n",
    "    'inference-schema[numpy-support]',\n",
    "    'joblib',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'sklearn',\n",
    "    'mlflow',\n",
    "    'matplotlib',\n",
    "    'seaborn'\n",
    "])\n",
    "\n",
    "# https://azure.github.io/azureml-cheatsheets/docs/cheatsheets/python/v1/environment/\n",
    "# add pip packages\n",
    "#conda.add_pip_package('pickle')\n",
    "#conda.add_pip_package('collections')\n",
    "\n",
    "trainenv.save_to_directory('environment/trainenv.yml', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Conda channels : https://docs.anaconda.com/anaconda/user-guide/tasks/using-repositories/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/trainenv.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/trainenv.yml\n",
    "\n",
    "name: trainenv\n",
    "channels:\n",
    "    - anaconda\n",
    "    - conda-forge\n",
    "dependencies:\n",
    "    - python=3.6.9\n",
    "    - pip\n",
    "    - pip:\n",
    "        - azureml-core\n",
    "        - azureml-defaults\n",
    "        - azureml-mlflow\n",
    "        - opencensus-ext-azure>=1.0.1\n",
    "        - inference-schema[numpy-support]\n",
    "        - joblib\n",
    "        - numpy\n",
    "        - pandas\n",
    "        - scikit-learn==0.24.1\n",
    "        - imbalanced-learn==0.8.0\n",
    "        - mlflow\n",
    "        - matplotlib\n",
    "        - seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "\n",
    "trainenv = Environment.from_conda_specification('trainenv', 'scripts/trainenv.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = 'scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "\n",
    "script_params = {\n",
    "    '--penalty': 'l2',\n",
    "    '--max_iter': 10000\n",
    "}\n",
    "\n",
    "estimator = Estimator(source_directory=script_folder,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target_name,\n",
    "              environment_definition=trainenv,\n",
    "              entry_script='train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ScriptRunConfig\n",
    "# https://docs.microsoft.com/fr-fr/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py\n",
    "# https://docs.microsoft.com/fr-fr/azure/machine-learning/how-to-migrate-from-estimators-to-scriptrunconfig\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "\n",
    "config = ScriptRunConfig(source_directory=script_folder,\n",
    "                        script='train.py',\n",
    "                        arguments=['--penalty', 'l2', '--max_iter', 10000],\n",
    "                        compute_target=compute_target_name,\n",
    "                        environment=trainenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>exp_german_credit</td><td>exp_german_credit_1623184873_8799d9fa</td><td>azureml.scriptrun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/exp_german_credit_1623184873_8799d9fa?wsid=/subscriptions/f80606e5-788f-4dc3-a9ea-2eb9a7836082/resourcegroups/rg-sandbox/workspaces/sandboxaml&amp;tid=8e2e7c2d-4702-496d-af6c-96e4bfc9f667\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: exp_german_credit,\n",
       "Id: exp_german_credit_1623184873_8799d9fa,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Preparing)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run = exp.submit(config=estimator)\n",
    "run = exp.submit(config=config)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e742e71c9c945db8a84546702366014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Finalizing\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/exp_german_credit_1623184873_8799d9fa?wsid=/subscriptions/f80606e5-788f-4dc3-a9ea-2eb9a7836082/resourcegroups/rg-sandbox/workspaces/sandboxaml&tid=8e2e7c2d-4702-496d-af6c-96e4bfc9f667\", \"run_id\": \"exp_german_credit_1623184873_8799d9fa\", \"run_properties\": {\"run_id\": \"exp_german_credit_1623184873_8799d9fa\", \"created_utc\": \"2021-06-08T20:41:17.111836Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"fd9f762a-7f59-4074-aff6-df2d87166183\", \"azureml.git.repository_uri\": \"methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks\", \"mlflow.source.git.repoURL\": \"methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"175da9d421962e1b3971a618aea8a1f856c3f8c5\", \"mlflow.source.git.commit\": \"175da9d421962e1b3971a618aea8a1f856c3f8c5\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\", \"mlflow.param.key.penalty\": \"l2\", \"mlflow.param.key.max_iter\": \"10000\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\", \"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"train.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Finalizing\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/55_azureml-execution-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt?sv=2019-02-02&sr=b&sig=JVXLAIcgxUB6VB1e4do%2BEio%2FzfGCiDnueMMaWD4e8W4%3D&st=2021-06-08T20%3A36%3A25Z&se=2021-06-09T04%3A46%3A25Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/65_job_prep-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt?sv=2019-02-02&sr=b&sig=2VsK97T%2BwB7g2FyH0QXyzWSInu3uBkTFaWAjwRm8264%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=pC7U4lhNN%2FOqJA29Ts8Jt%2Fo2u23J6t0VQ21V7pUeI5g%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\", \"azureml-logs/75_job_post-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/75_job_post-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt?sv=2019-02-02&sr=b&sig=Iay5mbVqlyjpIijB1CS3a3TghC0FdJ0K6uRefui%2B9hs%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\", \"azureml-logs/process_info.json\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=aak0RLnahJ%2F6kioxDoiFQRdlMbNeC4gvmgI1if3tutM%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\", \"azureml-logs/process_status.json\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=qzF5OFefWlmcSOqDiA2OOeaDNNEoef1YshX%2BNKFBPsQ%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\", \"logs/azureml/97_azureml.log\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/97_azureml.log?sv=2019-02-02&sr=b&sig=rFANetdkj3pOCOODiE21pXJfO57c08mSziPxz9%2BQMts%3D&st=2021-06-08T20%3A36%3A25Z&se=2021-06-09T04%3A46%3A25Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=U1hKzvgRuTcgC589Dykum8q7UhjYSsWuJklyafY3SAI%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=JtNqZthmk6m6W62X2jqvtISuv3lqclh1OthOa7b9wuw%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=%2FHzBE1e3FYfVS5zEmWhGdlb%2B6fSPuoTvSGWBphaMZDs%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=FUF2ZYKLuVRxNiZEUj5PFXPwduacBqYz1GYHMpzkbLU%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt\"], [\"logs/azureml/97_azureml.log\"]], \"run_duration\": \"0:05:09\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"train accuracy\", \"run_id\": \"exp_german_credit_1623184873_8799d9fa\", \"categories\": [0], \"series\": [{\"data\": [0.75625]}]}, {\"name\": \"test accuracy\", \"run_id\": \"exp_german_credit_1623184873_8799d9fa\", \"categories\": [0], \"series\": [{\"data\": [0.7]}]}, {\"name\": \"recall\", \"run_id\": \"exp_german_credit_1623184873_8799d9fa\", \"categories\": [0], \"series\": [{\"data\": [0.7134502923976608]}]}, {\"name\": \"f1\", \"run_id\": \"exp_german_credit_1623184873_8799d9fa\", \"categories\": [0], \"series\": [{\"data\": [0.8026315789473684]}]}], \"run_logs\": \"2021-06-08 20:45:56,854|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-06-08 20:45:56,854|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-06-08 20:45:56,879|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-06-08 20:45:56,879|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-06-08 20:45:57,387|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f739a7a8d08> for run source azureml.scriptrun\\n2021-06-08 20:45:57,389|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-08 20:45:57,389|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-08 20:45:57,390|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-08 20:45:57,398|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-06-08 20:45:57,398|azureml.core.authentication|DEBUG|Time to expire 1814119.601161 seconds\\n2021-06-08 20:45:57,399|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-06-08 20:45:57,399|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-06-08 20:45:57,441|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:57,442|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:57,443|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:57,443|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:57,443|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:57,443|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:57,444|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:57,482|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-06-08 20:45:57,482|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-08 20:45:57,571|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-08 20:45:57,572|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'fd9f762a-7f59-4074-aff6-df2d87166183', 'azureml.git.repository_uri': 'methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks', 'mlflow.source.git.repoURL': 'methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '175da9d421962e1b3971a618aea8a1f856c3f8c5', 'mlflow.source.git.commit': '175da9d421962e1b3971a618aea8a1f856c3f8c5', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-06-08 20:45:57,572|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-06-08 20:45:58,187|azureml|DEBUG|Installed with mlflow version 1.17.0.\\n2021-06-08 20:45:58,188|azureml.mlflow|DEBUG|Setting up a Remote MLflow run\\n2021-06-08 20:45:58,189|azureml.mlflow|DEBUG|Creating a tracking uri in westeurope.api.azureml.ms for workspace /subscriptions/f80606e5-788f-4dc3-a9ea-2eb9a7836082/resourceGroups/rg-sandbox/providers/Microsoft.MachineLearningServices/workspaces/sandboxaml\\n2021-06-08 20:45:58,189|azureml.mlflow|DEBUG|Setting MLflow tracking uri env var\\n2021-06-08 20:45:58,189|azureml.mlflow|DEBUG|Setting MLflow run id env var with exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:45:58,189|azureml.mlflow|DEBUG|Setting Mlflow experiment with exp_german_credit\\n2021-06-08 20:45:58,190|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.type\\n2021-06-08 20:45:58,191|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.name\\n2021-06-08 20:45:58,191|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[START]\\n2021-06-08 20:45:58,191|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_details with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/details\\n2021-06-08 20:45:58,307|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[STOP]\\n2021-06-08 20:45:58,311|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-06-08 20:45:58,311|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-08 20:45:58,543|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-08 20:45:58,543|azureml.WorkerPool|DEBUG|[START]\\n2021-06-08 20:45:58,543|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-06-08 20:45:58,543|azureml.RunStatusContext|DEBUG|[START]\\n2021-06-08 20:45:58,543|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-06-08 20:45:58,543|azureml.MetricsClient|DEBUG|[START]\\n2021-06-08 20:45:58,543|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-06-08 20:45:58,544|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-06-08 20:45:58,544|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-06-08 20:45:58,544|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/sandboxaml/azureml/exp_german_credit_1623184873_8799d9fa/mounts/workspaceblobstore/azureml/exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:45:58,544|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-06-08 20:45:58,544|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/sandboxaml/azureml/exp_german_credit_1623184873_8799d9fa/mounts/workspaceblobstore/azureml/exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:45:59,525|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-08 20:45:59,525|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-08 20:45:59,526|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-06-08 20:45:59,526|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,527|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,558|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-06-08 20:45:59,559|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-08 20:45:59,645|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-08 20:45:59,647|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'fd9f762a-7f59-4074-aff6-df2d87166183', 'azureml.git.repository_uri': 'methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks', 'mlflow.source.git.repoURL': 'methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '175da9d421962e1b3971a618aea8a1f856c3f8c5', 'mlflow.source.git.commit': '175da9d421962e1b3971a618aea8a1f856c3f8c5', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-06-08 20:45:59,647|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-06-08 20:45:59,944|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-08 20:45:59,945|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-08 20:45:59,945|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-06-08 20:45:59,947|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,948|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,950|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,951|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,956|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,956|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:45:59,956|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:46:07,508|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-06-08 20:46:07,508|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-06-08 20:46:07,508|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-06-08 20:46:07,509|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:46:07,509|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:46:07,509|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:46:07,510|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:46:07,510|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:46:07,510|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:46:07,510|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.api.azureml.ms.\\n2021-06-08 20:46:07,518|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2021-06-08 20:46:07,518|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-08 20:46:07,653|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:09,890|azureml.mlflow|DEBUG|Creating a tracking uri in westeurope.api.azureml.ms for workspace /subscriptions/f80606e5-788f-4dc3-a9ea-2eb9a7836082/resourceGroups/rg-sandbox/providers/Microsoft.MachineLearningServices/workspaces/sandboxaml\\n2021-06-08 20:46:09,891|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:09,892|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:10,094|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:10,094|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:10,236|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:10,236|azureml.mlflow._internal.store|DEBUG|Status update was skipped for remote run exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:46:10,236|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:10,388|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:10,388|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:10,522|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:10,523|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:10,673|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:10,673|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:10,932|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:10,932|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:11,221|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:11,221|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:11,517|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:11,517|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:11,890|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:11,890|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:12,121|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:12,121|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:12,259|azureml.mlflow._internal.utils|DEBUG|Initializing the AzureMLflowArtifactRepository\\n2021-06-08 20:46:12,260|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:12,260|azureml.mlflow._internal.utils|DEBUG|Using the service context from the AzureMLRestStore store\\n2021-06-08 20:46:12,260|azureml.mlflow._internal.utils|INFO|Parsing artifact uri azureml://experiments/exp_german_credit/runs/exp_german_credit_1623184873_8799d9fa/artifacts\\n2021-06-08 20:46:12,261|azureml.mlflow._internal.utils|INFO|Artifact uri azureml://experiments/exp_german_credit/runs/exp_german_credit_1623184873_8799d9fa/artifacts info: {'experiment': 'exp_german_credit', 'runid': 'exp_german_credit_1623184873_8799d9fa'}\\n2021-06-08 20:46:12,261|azureml.mlflow._internal.utils|DEBUG|AzureMLflowArtifactRepository for experiment exp_german_credit\\n2021-06-08 20:46:12,261|azureml.mlflow._internal.utils|DEBUG|AzureMLflowArtifactRepository for run id exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:46:12,261|azureml.mlflow._internal.utils|DEBUG|AzureMLflowArtifactRepository for path None\\n2021-06-08 20:46:12,261|azureml.RunArtifactRepositoryClient|DEBUG|Uploading ['german_credit_mlflow_log_model/MLmodel', 'german_credit_mlflow_log_model/conda.yaml', 'german_credit_mlflow_log_model/model.pkl']\\n2021-06-08 20:46:12,261|azureml.upload_files|DEBUG|[Start]\\n2021-06-08 20:46:12,263|azureml.RunArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-06-08 20:46:12,263|azureml.RunArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/artifacts/batch/metadata\\n2021-06-08 20:46:12,590|azureml.RunArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:12,591|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: perform_upload\\n2021-06-08 20:46:12,591|azureml.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2021-06-08 20:46:12,593|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-06-08 20:46:12,593|azureml.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2021-06-08 20:46:12,594|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: perform_upload\\n2021-06-08 20:46:12,599|azureml.upload_files.1_perform_upload|DEBUG|Using basic handler - no exception handling\\n2021-06-08 20:46:12,600|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-06-08 20:46:12,600|azureml.upload_files|DEBUG|Adding task 1_perform_upload to queue of approximate size: 1\\n2021-06-08 20:46:12,600|azureml._restclient.clientbase.WorkerPool|DEBUG|submitting future: perform_upload\\n2021-06-08 20:46:12,605|azureml.upload_files.2_perform_upload|DEBUG|Using basic handler - no exception handling\\n2021-06-08 20:46:12,605|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-06-08 20:46:12,605|azureml.upload_files|DEBUG|Adding task 2_perform_upload to queue of approximate size: 2\\n2021-06-08 20:46:12,606|azureml.upload_files|DEBUG|[Stop] - waiting default timeout\\n2021-06-08 20:46:12,609|azureml.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2021-06-08 20:46:12,609|azureml.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 120\\n2021-06-08 20:46:12,610|azureml.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_perform_upload), AsyncTask(1_perform_upload), AsyncTask(2_perform_upload)].\\n2021-06-08 20:46:12,667|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/german_credit_mlflow_log_model/model.pkl with size 870, file size 870.\\n2021-06-08 20:46:12,672|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/german_credit_mlflow_log_model/MLmodel with size 379, file size 379.\\n2021-06-08 20:46:12,676|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/german_credit_mlflow_log_model/conda.yaml with size 153, file size 153.\\n2021-06-08 20:46:12,860|azureml.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2021-06-08 20:46:12,861|azureml.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2021-06-08 20:46:12,861|azureml.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2021-06-08 20:46:12,861|azureml.upload_files.1_perform_upload.WaitingTask|DEBUG|[START]\\n2021-06-08 20:46:12,861|azureml.upload_files.1_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2021-06-08 20:46:12,861|azureml.upload_files.1_perform_upload.WaitingTask|DEBUG|[STOP]\\n2021-06-08 20:46:12,861|azureml.upload_files.2_perform_upload.WaitingTask|DEBUG|[START]\\n2021-06-08 20:46:12,862|azureml.upload_files.2_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2021-06-08 20:46:12,862|azureml.upload_files.2_perform_upload.WaitingTask|DEBUG|[STOP]\\n2021-06-08 20:46:12,862|azureml.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\nWaiting on task: 1_perform_upload.\\nWaiting on task: 2_perform_upload.\\n3 tasks left. Current duration of flush 0.00017404556274414062 seconds.\\n\\n2021-06-08 20:46:12,862|azureml.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2021-06-08 20:46:12,866|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:12,867|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:13,410|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.ArtifactsClient|DEBUG|Fetching files for prefix in ExperimentRun, dcid.exp_german_credit_1623184873_8799d9fa, german_credit_mlflow_log_model/model.pkl\\n2021-06-08 20:46:13,410|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[START]\\n2021-06-08 20:46:13,411|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _execute_with_base_arguments\\n2021-06-08 20:46:13,411|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling list_sas_by_prefix with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/prefix/contentinfo/{origin}/{container}/{path}\\n2021-06-08 20:46:13,412|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix|DEBUG|Using basic handler - no exception handling\\n2021-06-08 20:46:13,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix-async:True|DEBUG|[STOP]\\n2021-06-08 20:46:13,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[START]\\n2021-06-08 20:46:13,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|Awaiter is ApiPagination\\n2021-06-08 20:46:13,569|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.ArtifactsClient.list_sas_by_prefix.WaitingTask|DEBUG|[STOP]\\n2021-06-08 20:46:13,569|azureml._restclient.clientbase|DEBUG|Found continuation_token field in DTO\\n2021-06-08 20:46:13,570|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[START]\\n2021-06-08 20:46:13,570|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.AssetsClient|DEBUG|ClientBase: Calling create with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/assets\\n2021-06-08 20:46:13,674|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.AssetsClient.create-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:13,683|azureml.ModelsClient.register-async:False|DEBUG|[START]\\n2021-06-08 20:46:13,683|azureml.ModelsClient|DEBUG|ClientBase: Calling register with url /modelmanagement/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.MachineLearningServices/workspaces/{workspace}/models\\n2021-06-08 20:46:13,983|azureml.ModelsClient.register-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:13,985|azureml.WorkspaceClient.get-async:False|DEBUG|[START]\\n2021-06-08 20:46:13,985|azureml.WorkspaceClient|DEBUG|ClientBase: Calling get with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}\\n2021-06-08 20:46:14,076|azureml.WorkspaceClient.get-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:14,077|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-06-08 20:46:14,077|azureml.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-06-08 20:46:14,154|azureml.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:14,155|azureml.core.run|DEBUG|Available factories for run types {'azureml.scriptrun': <function ScriptRun._from_run_dto at 0x7f739a7a8d08>}\\n2021-06-08 20:46:14,155|azureml.core.run|DEBUG|Initializing Run exp_german_credit_1623184873_8799d9fa from type azureml.scriptrun\\n2021-06-08 20:46:14,158|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'fd9f762a-7f59-4074-aff6-df2d87166183', 'azureml.git.repository_uri': 'methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks', 'mlflow.source.git.repoURL': 'methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '175da9d421962e1b3971a618aea8a1f856c3f8c5', 'mlflow.source.git.commit': '175da9d421962e1b3971a618aea8a1f856c3f8c5', 'azureml.git.dirty': 'True', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'mlflow.param.key.penalty': 'l2', 'mlflow.param.key.max_iter': '10000'}\\n2021-06-08 20:46:14,159|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-06-08 20:46:14,159|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2021-06-08 20:46:14,159|azureml.mlflow._internal.store|DEBUG|Status update was skipped for remote run exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:46:14,159|azureml._restclient.clientbase|DEBUG|ClientBase: Calling _call_endpoint with url None\\n2021-06-08 20:46:14,414|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-06-08 20:46:14,414|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/sandboxaml/azureml/exp_german_credit_1623184873_8799d9fa/mounts/workspaceblobstore/azureml/exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:46:14,414|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/sandboxaml/azureml/exp_german_credit_1623184873_8799d9fa/mounts/workspaceblobstore/azureml/exp_german_credit_1623184873_8799d9fa to /mnt/batch/tasks/shared/LS_root/jobs/sandboxaml/azureml/exp_german_credit_1623184873_8799d9fa/mounts/workspaceblobstore/azureml/exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:46:14,415|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/sandboxaml/azureml/exp_german_credit_1623184873_8799d9fa/mounts/workspaceblobstore/azureml/exp_german_credit_1623184873_8799d9fa\\n2021-06-08 20:46:14,415|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-06-08 20:46:14,415|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-06-08 20:46:14,415|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,415|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-08 20:46:14,415|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-08 20:46:14,415|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-08 20:46:14,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-06-08 20:46:14,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-08 20:46:14,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,416|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-08 20:46:14,417|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-08 20:46:14,417|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-08 20:46:14,417|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,417|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,417|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-06-08 20:46:14,417|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-08 20:46:14,418|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,418|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,418|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-08 20:46:14,418|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-08 20:46:14,507|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:14,508|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,508|azureml.MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,508|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,509|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,509|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,509|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-06-08 20:46:14,509|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-08 20:46:14,509|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,509|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,509|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,509|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-06-08 20:46:14,510|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-08 20:46:14,510|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,510|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,510|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-08 20:46:14,510|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-08 20:46:14,603|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:14,603|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-06-08 20:46:14,603|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,603|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-08 20:46:14,604|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-08 20:46:14,687|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:14,687|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,687|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-08 20:46:14,688|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-08 20:46:14,688|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-08 20:46:14,688|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,688|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,688|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-08 20:46:14,689|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-08 20:46:14,689|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,689|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-08 20:46:14,689|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-08 20:46:14,689|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-08 20:46:14,690|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,690|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,690|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-08 20:46:14,690|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-08 20:46:14,690|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,690|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,690|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-08 20:46:14,690|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-08 20:46:14,778|azureml._SubmittedRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:14,779|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,779|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-08 20:46:14,779|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-08 20:46:14,780|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-08 20:46:14,780|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,780|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,780|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-08 20:46:14,780|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-06-08 20:46:14,780|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,781|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-06-08 20:46:14,781|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-06-08 20:46:14,782|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-06-08 20:46:14,782|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-06-08 20:46:14,782|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-06-08 20:46:14,782|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-06-08 20:46:14,782|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-06-08 20:46:14,783|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,783|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-06-08 20:46:14,783|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-06-08 20:46:14,783|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-06-08 20:46:14,877|azureml.ScriptRun#exp_german_credit_1623184873_8799d9fa.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-06-08 20:46:14,877|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-06-08 20:46:14,878|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-06-08 20:46:14,878|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-06-08 20:46:14,878|azureml.WorkerPool|DEBUG|[STOP]\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.30.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: exp_german_credit_1623184873_8799d9fa\n",
      "Web View: https://ml.azure.com/runs/exp_german_credit_1623184873_8799d9fa?wsid=/subscriptions/f80606e5-788f-4dc3-a9ea-2eb9a7836082/resourcegroups/rg-sandbox/workspaces/sandboxaml&tid=8e2e7c2d-4702-496d-af6c-96e4bfc9f667\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-06-08T20:45:50.194346] Entering job preparation.\n",
      "[2021-06-08T20:45:51.619326] Starting job preparation.\n",
      "[2021-06-08T20:45:51.619380] Extracting the control code.\n",
      "[2021-06-08T20:45:51.640339] fetching and extracting the control code on master node.\n",
      "[2021-06-08T20:45:51.640375] Starting extract_project.\n",
      "[2021-06-08T20:45:51.640418] Starting to extract zip file.\n",
      "[2021-06-08T20:45:52.166462] Finished extracting zip file.\n",
      "[2021-06-08T20:45:52.346078] Using urllib.request Python 3.0 or later\n",
      "[2021-06-08T20:45:52.346151] Start fetching snapshots.\n",
      "[2021-06-08T20:45:52.346199] Start fetching snapshot.\n",
      "[2021-06-08T20:45:52.346223] Retrieving project from snapshot: fd9f762a-7f59-4074-aff6-df2d87166183\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 43\n",
      "[2021-06-08T20:45:53.130399] Finished fetching snapshot.\n",
      "[2021-06-08T20:45:53.130462] Finished fetching snapshots.\n",
      "[2021-06-08T20:45:53.130491] Finished extract_project.\n",
      "[2021-06-08T20:45:53.143811] Finished fetching and extracting the control code.\n",
      "[2021-06-08T20:45:53.149239] downloadDataStore - Download from datastores if requested.\n",
      "[2021-06-08T20:45:53.151146] Start run_history_prep.\n",
      "[2021-06-08T20:45:53.262797] Entering context manager injector.\n",
      "[2021-06-08T20:45:53.317888] downloadDataStore completed\n",
      "[2021-06-08T20:45:53.320881] Job preparation is complete.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-06-08T20:46:21.999652] Entering job release\n",
      "[2021-06-08T20:46:23.125145] Starting job release\n",
      "[2021-06-08T20:46:23.126016] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 350\n",
      "[2021-06-08T20:46:23.126398] job release stage : upload_datastore starting...\n",
      "[2021-06-08T20:46:23.130311] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-06-08T20:46:23.130493] job release stage : execute_job_release starting...\n",
      "[2021-06-08T20:46:23.137691] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-06-08T20:46:23.137731] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-06-08T20:46:23.138308] Entering context manager injector.\n",
      "[2021-06-08T20:46:23.140355] job release stage : upload_datastore completed...\n",
      "[2021-06-08T20:46:23.425565] job release stage : execute_job_release completed...\n",
      "[2021-06-08T20:46:23.449028] job release stage : send_run_telemetry starting...\n",
      "[2021-06-08T20:46:23.618216] get vm size and vm region successfully.\n",
      "[2021-06-08T20:46:24.314306] get compute meta data successfully.\n",
      "[2021-06-08T20:46:24.597334] post artifact meta request successfully.\n",
      "[2021-06-08T20:46:24.629130] upload compute record artifact successfully.\n",
      "[2021-06-08T20:46:24.629229] job release stage : send_run_telemetry completed...\n",
      "[2021-06-08T20:46:24.629527] Job release is complete\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: exp_german_credit_1623184873_8799d9fa\n",
      "Web View: https://ml.azure.com/runs/exp_german_credit_1623184873_8799d9fa?wsid=/subscriptions/f80606e5-788f-4dc3-a9ea-2eb9a7836082/resourcegroups/rg-sandbox/workspaces/sandboxaml&tid=8e2e7c2d-4702-496d-af6c-96e4bfc9f667\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'exp_german_credit_1623184873_8799d9fa',\n",
       " 'target': 'compute-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-06-08T20:45:24.171666Z',\n",
       " 'endTimeUtc': '2021-06-08T20:46:34.117923Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'fd9f762a-7f59-4074-aff6-df2d87166183',\n",
       "  'azureml.git.repository_uri': 'methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks',\n",
       "  'mlflow.source.git.repoURL': 'methodidacte@vs-ssh.visualstudio.com:v3/methodidacte/azuremlnotebooks/azuremlnotebooks',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '175da9d421962e1b3971a618aea8a1f856c3f8c5',\n",
       "  'mlflow.source.git.commit': '175da9d421962e1b3971a618aea8a1f856c3f8c5',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json',\n",
       "  'mlflow.param.key.penalty': 'l2',\n",
       "  'mlflow.param.key.max_iter': '10000'},\n",
       " 'inputDatasets': [{'dataset': {'id': '539a61ca-de27-47bc-8472-8687ee90dd53'}, 'consumptionDetails': {'type': 'Reference'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--penalty', 'l2', '--max_iter', '10000'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'compute-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'trainenv',\n",
       "   'version': 'Autosave_2021-06-08T18:42:35Z_f7079334',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.9',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-core',\n",
       "        'azureml-defaults',\n",
       "        'azureml-mlflow',\n",
       "        'opencensus-ext-azure>=1.0.1',\n",
       "        'inference-schema[numpy-support]',\n",
       "        'joblib',\n",
       "        'numpy',\n",
       "        'pandas',\n",
       "        'scikit-learn==0.24.1',\n",
       "        'imbalanced-learn==0.8.0',\n",
       "        'mlflow',\n",
       "        'matplotlib',\n",
       "        'seaborn']}],\n",
       "     'name': 'azureml_5f9224b11317bf0f6fafacd7dfa80a3d'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210513.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/55_azureml-execution-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt?sv=2019-02-02&sr=b&sig=JVXLAIcgxUB6VB1e4do%2BEio%2FzfGCiDnueMMaWD4e8W4%3D&st=2021-06-08T20%3A36%3A25Z&se=2021-06-09T04%3A46%3A25Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/65_job_prep-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt?sv=2019-02-02&sr=b&sig=2VsK97T%2BwB7g2FyH0QXyzWSInu3uBkTFaWAjwRm8264%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=pC7U4lhNN%2FOqJA29Ts8Jt%2Fo2u23J6t0VQ21V7pUeI5g%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/75_job_post-tvmps_5fc14c69b009f20fa8e89b42d0d27c21057a0a892d64ddba758ffa270043cc95_d.txt?sv=2019-02-02&sr=b&sig=Iay5mbVqlyjpIijB1CS3a3TghC0FdJ0K6uRefui%2B9hs%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=aak0RLnahJ%2F6kioxDoiFQRdlMbNeC4gvmgI1if3tutM%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=qzF5OFefWlmcSOqDiA2OOeaDNNEoef1YshX%2BNKFBPsQ%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r',\n",
       "  'logs/azureml/97_azureml.log': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/97_azureml.log?sv=2019-02-02&sr=b&sig=rFANetdkj3pOCOODiE21pXJfO57c08mSziPxz9%2BQMts%3D&st=2021-06-08T20%3A36%3A25Z&se=2021-06-09T04%3A46%3A25Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=U1hKzvgRuTcgC589Dykum8q7UhjYSsWuJklyafY3SAI%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=JtNqZthmk6m6W62X2jqvtISuv3lqclh1OthOa7b9wuw%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=%2FHzBE1e3FYfVS5zEmWhGdlb%2B6fSPuoTvSGWBphaMZDs%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://sandboxaml8609434243.blob.core.windows.net/azureml/ExperimentRun/dcid.exp_german_credit_1623184873_8799d9fa/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=FUF2ZYKLuVRxNiZEUj5PFXPwduacBqYz1GYHMpzkbLU%3D&st=2021-06-08T20%3A36%3A26Z&se=2021-06-09T04%3A46%3A26Z&sp=r'},\n",
       " 'submittedBy': 'Paul PETON'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify show_output to True for a verbose log\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> WARNING: A newer version of conda exists. <==\n",
    "  current version: 4.9.2\n",
    "  latest version: 4.10.1\n",
    "\n",
    "Please update conda by running\n",
    "\n",
    "    $ conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/media/how-to-track-experiments/mlflow-diagram-track.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/score.py\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sklearn\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "\n",
    "\n",
    "# The init() method is called once, when the web service starts up.\n",
    "#\n",
    "# Typically you would deserialize the model file, as shown here using joblib,\n",
    "# and store it in a global variable so your run() method can access it later.\n",
    "def init():\n",
    "    global model\n",
    "\n",
    "    # The AZUREML_MODEL_DIR environment variable indicates\n",
    "    # a directory containing the model file you registered.\n",
    "    model_filename = 'german_credit_log_model.pkl'\n",
    "    model_path = os.path.join(os.environ['AZUREML_MODEL_DIR'], model_filename)\n",
    "    #ModuleNotFoundError: No module named 'sklearn.externals.joblib'\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "# The run() method is called each time a request is made to the scoring API.\n",
    "#\n",
    "# Shown here are the optional input_schema and output_schema decorators\n",
    "# from the inference-schema pip package. Using these decorators on your\n",
    "# run() method parses and validates the incoming payload against\n",
    "# the example input you provide here. This will also generate a Swagger\n",
    "# API document for your web service.\n",
    "#@input_schema('data', NumpyParameterType(np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])))\n",
    "#@output_schema(NumpyParameterType(np.array([0])))\n",
    "\n",
    "def run(raw_data):\n",
    "    data = json.loads(raw_data)['data']\n",
    "    method = json.loads(raw_data)['method']\n",
    "    # Use the model object loaded by init().\n",
    "    result = model.predict(data) if method==\"predict\" else model.predict_proba(data)\n",
    "\n",
    "    # You can return any JSON-serializable object.\n",
    "    return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "environment = Environment('german-credit-deploy-env')\n",
    "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-defaults',\n",
    "    'inference-schema[numpy-support]',\n",
    "    'joblib',\n",
    "    'numpy',\n",
    "    'sklearn'\n",
    "])\n",
    "\n",
    "environment.save_to_directory('environment/infenv.yml', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/infenv.yml\n",
    "\n",
    "name: project_environment\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - inference-schema[numpy-support]\n",
    "  - joblib\n",
    "  - numpy\n",
    "  - sklearn\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = 'german-credit-custom-srv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Webservice\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "\n",
    "# Remove any existing service under the same name.\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    pass\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, auth_enabled=False)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seulement si auth_enabled=True\n",
    "#print(service.get_keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({ \n",
    "    \"data\": [\n",
    "        [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        #,['0<=X<200',24,'existing paid','radio/tv',5951,'<100','1<=X<4',2,'female div/dep/mar','none',2,'real estate',22,'none','own',1,'skilled',1,'none','yes']\n",
    "    ],\n",
    "    \"method\": \"predict\"  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({ \n",
    "    \"data\": [\n",
    "        [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        #,['0<=X<200',24,'existing paid','radio/tv',5951,'<100','1<=X<4',2,'female div/dep/mar','none',2,'real estate',22,'none','own',1,'skilled',1,'none','yes']\n",
    "    ],\n",
    "    \"method\": \"predict_proba\"  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "#input_data = \"{\\\"data\\\": [[\\\"0<=X<200\\\",48,\\\"existing paid\\\",\\\"radio/tv\\\",5951,\\\"<100\\\",\\\"1<=X<4\\\",2,\\\"female div/dep/mar\\\",\\\"none\\\",2,\\\"real estate\\\",22,\\\"none\\\",\\\"own\\\",1,\\\"skilled\\\",1,\\\"none\\\",\\\"yes\\\"]]}\"\n",
    "input_data = \"{\\\"data\\\": [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "# for AKS deployment you'd need to the service key in the header as well\n",
    "api_key = service.get_keys()[0]\n",
    "headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/machine-learning/how-to-machine-learning-interpretability-aml.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remote run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ExplanationClient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4862dfb7da01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# importance des caract√©ristiques trait√©es √† partir de la meilleure ex√©cution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExplanationClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExplanationClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mengineered_explanations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_model_explanation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ExplanationClient'"
     ]
    }
   ],
   "source": [
    "# importance des caract√©ristiques trait√©es √† partir de la meilleure ex√©cution\n",
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "client = ExplanationClient.from_run(run)\n",
    "engineered_explanations = client.download_model_explanation(raw=False)\n",
    "#print(engineered_explanations.get_feature_importance_dict())\n",
    "\n",
    "engineered_dict = engineered_explanations.get_feature_importance_dict()\n",
    "engineered_df = pd.DataFrame(engineered_dict.items(), columns=['Engineered_feature', 'Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance des caract√©ristiques brutes √† partir de la meilleure ex√©cution \n",
    "from azureml.interpret import ExplanationClient\n",
    "\n",
    "client = ExplanationClient.from_run(run)\n",
    "raw_explanations = client.download_model_explanation(raw=True)\n",
    "print(raw_explanations.get_feature_importance_dict())\n",
    "\n",
    "raw_dict = raw_explanations.get_feature_importance_dict()\n",
    "raw_df = pd.DataFrame(raw_dict.items(), columns=['Raw_feature', 'Value'])\n",
    "\n",
    "#Explanation asset ID None was not found to match the supplied filters ['comment', 'raw']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[raw_df['Value']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.runtime.automl_explain_utilities import automl_setup_model_explanations\n",
    "\n",
    "X_train = train_data.to_pandas_dataframe().drop(target, axis=1)\n",
    "y_train = train_data.to_pandas_dataframe()[[target]]\n",
    "\n",
    "automl_explainer_setup_obj = automl_setup_model_explanations(fitted_model, X=X_train, \n",
    "                                                             X_test=X_test.drop([target, 'score', 'gap', 'gap w/sign'], axis=1), y=y_test,\n",
    "                                                             task='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.interpret import MimicWrapper\n",
    "\n",
    "# Initialize the Mimic Explainer\n",
    "explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator,\n",
    "                         explainable_model=automl_explainer_setup_obj.surrogate_model, \n",
    "                         init_dataset=automl_explainer_setup_obj.X_transform, run=automl_run,\n",
    "                         features=automl_explainer_setup_obj.engineered_feature_names, \n",
    "                         feature_maps=[automl_explainer_setup_obj.feature_map],\n",
    "                         model_task='regression',\n",
    "                         #classes=automl_explainer_setup_obj.classes,\n",
    "                         explainer_kwargs=automl_explainer_setup_obj.surrogate_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engineered_explanations = explainer.explain(['local', 'global'], eval_dataset=automl_explainer_setup_obj.X_test_transform)\n",
    "print(engineered_explanations.get_feature_importance_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret_community.widget import ExplanationDashboard\n",
    "\n",
    "ExplanationDashboard(raw_explanations, automl_explainer_setup_obj.automl_pipeline, datasetX=automl_explainer_setup_obj.X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.interpret.scoring.scoring_explainer import TreeScoringExplainer, save\n",
    "\n",
    "# Initialize the ScoringExplainer\n",
    "scoring_explainer = TreeScoringExplainer(explainer.explainer, feature_maps=[automl_explainer_setup_obj.feature_map])\n",
    "\n",
    "# Pickle scoring explainer locally\n",
    "save(scoring_explainer, exist_ok=True)\n",
    "\n",
    "# Register trained automl model present in the 'outputs' folder in the artifacts\n",
    "original_model = automl_run.register_model(model_name='automl_model', \n",
    "                                           model_path='outputs/model.pkl')\n",
    "\n",
    "# Register scoring explainer\n",
    "automl_run.upload_file('scoring_explainer.pkl', 'scoring_explainer.pkl')\n",
    "scoring_explainer_model = automl_run.register_model(model_name='scoring_explainer', model_path='scoring_explainer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
